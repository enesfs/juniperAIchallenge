{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enesfs/juniperAIchallenge/blob/main/JuniperAIchallenge_efs01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from locale import D_FMT\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "df = pd.read_csv(\"training_dataset_first10.csv\", sep = ',', index_col = 0)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "19DDjl74jJvA",
        "outputId": "ec64eaa3-58aa-4525-9f7a-9a37b33ae9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         observation_id observation_timestamp  hour_of_day  \\\n",
              "0  704d2a80-d52e-11ec-90ff-c7e6292284b3      16.05.2022 15:39           15   \n",
              "1  1cacc1d0-e6ac-11ec-b65d-156af70ce36b       7.06.2022 21:52           21   \n",
              "2  6dc2b330-d37a-11ec-884e-dfe9ea4a7bd5      14.05.2022 11:38           11   \n",
              "3  163ee0a0-0cca-11ed-a73c-8904b24187cc      26.07.2022 10:02           10   \n",
              "4  5e3c5df0-d5ee-11ec-a5f2-3b6f99e95850      17.05.2022 14:33           14   \n",
              "\n",
              "   register__sales_dollar_amt_this_hour register__payment_types_accepted  \\\n",
              "0                                347.29                      Cash+Credit   \n",
              "1                                361.59                      Cash+Credit   \n",
              "2                                850.73                      Cash+Credit   \n",
              "3                               1175.69                      Cash+Credit   \n",
              "4                               3204.53                      Cash+Credit   \n",
              "\n",
              "   register__peak_sales_dollar_amt_per_hour  \\\n",
              "0                                   -0.7383   \n",
              "1                                    0.6483   \n",
              "2                                   -0.4950   \n",
              "3                                   -0.5594   \n",
              "4                                    0.5693   \n",
              "\n",
              "   register__sales_dollar_amt_last_hour  register__sales_quantity_last_hour  \\\n",
              "0                               -0.1270                             -0.1993   \n",
              "1                               -0.0362                             -0.0777   \n",
              "2                               -0.1268                             -0.1974   \n",
              "3                               -0.1270                             -0.1991   \n",
              "4                               -0.1221                             -0.1632   \n",
              "\n",
              "   register__sales_quantity_rescanned_frac  \\\n",
              "0                                  -0.8299   \n",
              "1                                  -0.7395   \n",
              "2                                  13.1390   \n",
              "3                                  -0.8299   \n",
              "4                                  -0.7071   \n",
              "\n",
              "   register__sales_payments_declined_frac  ...  \\\n",
              "0                                 -0.1247  ...   \n",
              "1                                 -0.1135  ...   \n",
              "2                                  0.1075  ...   \n",
              "3                                 -0.1247  ...   \n",
              "4                                 -0.1247  ...   \n",
              "\n",
              "   region__sales_dollar_amt_last_hour  region__returns_dollar_amt_last_hour  \\\n",
              "0                             -0.6920                               -0.4605   \n",
              "1                             -0.6531                               -0.4434   \n",
              "2                             -0.6120                               -0.1786   \n",
              "3                             -0.5472                                0.1246   \n",
              "4                             -0.3838                                0.1996   \n",
              "\n",
              "   region__nighttime_open_registers  \\\n",
              "0                           -0.5180   \n",
              "1                           -0.6498   \n",
              "2                           -0.6040   \n",
              "3                           -0.5925   \n",
              "4                           -0.5696   \n",
              "\n",
              "   region__nighttime_service_time_per_customer  \\\n",
              "0                                     -10.0620   \n",
              "1                                       0.9031   \n",
              "2                                     -14.2290   \n",
              "3                                     -14.0970   \n",
              "4                                      11.2310   \n",
              "\n",
              "   region__nighttime_sales_amt_per_hour  \\\n",
              "0                               -0.6462   \n",
              "1                               -0.6493   \n",
              "2                               -0.6456   \n",
              "3                               -0.6478   \n",
              "4                               -0.6475   \n",
              "\n",
              "   region__nighttime_returns_amt_per_hour  \\\n",
              "0                                 -0.6030   \n",
              "1                                 -0.6106   \n",
              "2                                 -0.6037   \n",
              "3                                 -0.6079   \n",
              "4                                 -0.6032   \n",
              "\n",
              "   region__peak_sales_dollar_amt_per_hour  \\\n",
              "0                                 -0.4773   \n",
              "1                                  0.4998   \n",
              "2                                 19.3370   \n",
              "3                                  0.1288   \n",
              "4                                  1.0050   \n",
              "\n",
              "   region__peak_sales_dollar_amt_per_hour_v2  \\\n",
              "0                                     0.1748   \n",
              "1                                    -0.9816   \n",
              "2                                    -0.9093   \n",
              "3                                    -0.9093   \n",
              "4                                     0.1748   \n",
              "\n",
              "   region__peak_returns_dollar_amt_per_hour  \\\n",
              "0                                  -17.9510   \n",
              "1                                    0.8939   \n",
              "2                                   24.0460   \n",
              "3                                   -0.4983   \n",
              "4                                    1.5660   \n",
              "\n",
              "  region__peak_returns_dollar_amt_per_hour_v2  \n",
              "0                                     -0.8284  \n",
              "1                                     -0.8614  \n",
              "2                                     -0.7567  \n",
              "3                                     -0.7567  \n",
              "4                                      0.2356  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e04eaf7-f042-431d-92bf-670d7b436790\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>observation_id</th>\n",
              "      <th>observation_timestamp</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>register__sales_dollar_amt_this_hour</th>\n",
              "      <th>register__payment_types_accepted</th>\n",
              "      <th>register__peak_sales_dollar_amt_per_hour</th>\n",
              "      <th>register__sales_dollar_amt_last_hour</th>\n",
              "      <th>register__sales_quantity_last_hour</th>\n",
              "      <th>register__sales_quantity_rescanned_frac</th>\n",
              "      <th>register__sales_payments_declined_frac</th>\n",
              "      <th>...</th>\n",
              "      <th>region__sales_dollar_amt_last_hour</th>\n",
              "      <th>region__returns_dollar_amt_last_hour</th>\n",
              "      <th>region__nighttime_open_registers</th>\n",
              "      <th>region__nighttime_service_time_per_customer</th>\n",
              "      <th>region__nighttime_sales_amt_per_hour</th>\n",
              "      <th>region__nighttime_returns_amt_per_hour</th>\n",
              "      <th>region__peak_sales_dollar_amt_per_hour</th>\n",
              "      <th>region__peak_sales_dollar_amt_per_hour_v2</th>\n",
              "      <th>region__peak_returns_dollar_amt_per_hour</th>\n",
              "      <th>region__peak_returns_dollar_amt_per_hour_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>704d2a80-d52e-11ec-90ff-c7e6292284b3</td>\n",
              "      <td>16.05.2022 15:39</td>\n",
              "      <td>15</td>\n",
              "      <td>347.29</td>\n",
              "      <td>Cash+Credit</td>\n",
              "      <td>-0.7383</td>\n",
              "      <td>-0.1270</td>\n",
              "      <td>-0.1993</td>\n",
              "      <td>-0.8299</td>\n",
              "      <td>-0.1247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.6920</td>\n",
              "      <td>-0.4605</td>\n",
              "      <td>-0.5180</td>\n",
              "      <td>-10.0620</td>\n",
              "      <td>-0.6462</td>\n",
              "      <td>-0.6030</td>\n",
              "      <td>-0.4773</td>\n",
              "      <td>0.1748</td>\n",
              "      <td>-17.9510</td>\n",
              "      <td>-0.8284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1cacc1d0-e6ac-11ec-b65d-156af70ce36b</td>\n",
              "      <td>7.06.2022 21:52</td>\n",
              "      <td>21</td>\n",
              "      <td>361.59</td>\n",
              "      <td>Cash+Credit</td>\n",
              "      <td>0.6483</td>\n",
              "      <td>-0.0362</td>\n",
              "      <td>-0.0777</td>\n",
              "      <td>-0.7395</td>\n",
              "      <td>-0.1135</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.6531</td>\n",
              "      <td>-0.4434</td>\n",
              "      <td>-0.6498</td>\n",
              "      <td>0.9031</td>\n",
              "      <td>-0.6493</td>\n",
              "      <td>-0.6106</td>\n",
              "      <td>0.4998</td>\n",
              "      <td>-0.9816</td>\n",
              "      <td>0.8939</td>\n",
              "      <td>-0.8614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6dc2b330-d37a-11ec-884e-dfe9ea4a7bd5</td>\n",
              "      <td>14.05.2022 11:38</td>\n",
              "      <td>11</td>\n",
              "      <td>850.73</td>\n",
              "      <td>Cash+Credit</td>\n",
              "      <td>-0.4950</td>\n",
              "      <td>-0.1268</td>\n",
              "      <td>-0.1974</td>\n",
              "      <td>13.1390</td>\n",
              "      <td>0.1075</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.6120</td>\n",
              "      <td>-0.1786</td>\n",
              "      <td>-0.6040</td>\n",
              "      <td>-14.2290</td>\n",
              "      <td>-0.6456</td>\n",
              "      <td>-0.6037</td>\n",
              "      <td>19.3370</td>\n",
              "      <td>-0.9093</td>\n",
              "      <td>24.0460</td>\n",
              "      <td>-0.7567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>163ee0a0-0cca-11ed-a73c-8904b24187cc</td>\n",
              "      <td>26.07.2022 10:02</td>\n",
              "      <td>10</td>\n",
              "      <td>1175.69</td>\n",
              "      <td>Cash+Credit</td>\n",
              "      <td>-0.5594</td>\n",
              "      <td>-0.1270</td>\n",
              "      <td>-0.1991</td>\n",
              "      <td>-0.8299</td>\n",
              "      <td>-0.1247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5472</td>\n",
              "      <td>0.1246</td>\n",
              "      <td>-0.5925</td>\n",
              "      <td>-14.0970</td>\n",
              "      <td>-0.6478</td>\n",
              "      <td>-0.6079</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>-0.9093</td>\n",
              "      <td>-0.4983</td>\n",
              "      <td>-0.7567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5e3c5df0-d5ee-11ec-a5f2-3b6f99e95850</td>\n",
              "      <td>17.05.2022 14:33</td>\n",
              "      <td>14</td>\n",
              "      <td>3204.53</td>\n",
              "      <td>Cash+Credit</td>\n",
              "      <td>0.5693</td>\n",
              "      <td>-0.1221</td>\n",
              "      <td>-0.1632</td>\n",
              "      <td>-0.7071</td>\n",
              "      <td>-0.1247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3838</td>\n",
              "      <td>0.1996</td>\n",
              "      <td>-0.5696</td>\n",
              "      <td>11.2310</td>\n",
              "      <td>-0.6475</td>\n",
              "      <td>-0.6032</td>\n",
              "      <td>1.0050</td>\n",
              "      <td>0.1748</td>\n",
              "      <td>1.5660</td>\n",
              "      <td>0.2356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e04eaf7-f042-431d-92bf-670d7b436790')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e04eaf7-f042-431d-92bf-670d7b436790 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e04eaf7-f042-431d-92bf-670d7b436790');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AJM-oJSzHvw"
      },
      "outputs": [],
      "source": [
        "\n",
        "#sns.pairplot(data)\n",
        "\n",
        "#min_max=preprocessing.MinMaxScaler() #normalizasyon\n",
        "#col= data.columns\n",
        "#result=min_max.fit_transform(data)\n",
        "#df=pd.DataFrame(result, columns=col)\n",
        "\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=np.array(df['register__sales_dollar_amt_this_hour'])\n",
        "X=np.array(df.drop(['store__type_code','register__sales_dollar_amt_this_hour','register__payment_types_accepted','observation_timestamp','observation_id'],axis=1))\n",
        "\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.33,random_state=2)\n",
        "\n",
        "X_train =X_train[~np.isnan(X_train)]\n",
        "X_test =X_test[~np.isnan(X_test)]\n",
        "Y_train =Y_train[~np.isnan(Y_train)]\n",
        "Y_test =Y_test[~np.isnan(Y_test)]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "czOizNpGkI-H",
        "outputId": "5eb5373b-c663-4cbf-9fbc-e999d9f0fd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b1a52b36cc1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_call\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         )\n\u001b[1;32m    849\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1.5000e+01 -7.3830e-01 -1.2700e-01 -1.9930e-01 -8.2990e-01 -1.2470e-01\n -5.7210e-01 -2.5820e-01 -2.6210e-01 -5.3370e-01 -2.6036e+01 -2.5371e+01\n  1.0551e+01  9.1560e-01  6.7730e-01  4.5640e-01 -9.2000e-03  8.4320e-01\n -6.4490e-01  5.8000e-02 -3.6570e-01  1.6570e-01  4.6400e-01 -3.9090e-01\n -6.3250e-01 -7.0990e-01 -4.3860e-01 -5.6880e-01  7.2100e-02 -8.8380e-01\n -5.6140e-01  6.3760e-01  1.7890e-01  3.8400e-01 -3.0930e-01 -5.4870e-01\n -5.8710e-01 -1.2400e-02 -4.0950e-01 -4.3080e-01 -5.2740e-01 -3.3010e-01\n -2.8470e-01 -7.5990e-01 -5.9780e-01 -9.2550e-01 -3.8910e-01 -6.9200e-01\n -4.6050e-01 -5.1800e-01 -1.0062e+01 -6.4620e-01 -6.0300e-01 -4.7730e-01\n  1.7480e-01 -1.7951e+01 -8.2840e-01  1.5000e+01 -6.2410e-01 -8.9400e-02\n -1.2400e-01 -2.2730e-01 -1.2470e-01 -2.4820e-01 -2.3190e-01 -1.6240e-01\n  3.8200e-02 -3.5200e-01 -7.4540e-01 -5.4070e-01 -1.6604e+01 -1.4071e+01\n  1.9730e-01 -2.1570e-01 -9.2310e-01  9.9700e-02 -2.9600e-01 -3.6570e-01\n -6.3710e-01 -2.3180e-01 -3.9090e-01 -4.5900e-01 -2.1950e-01 -1.1890e-01\n -1.7460e-01 -1.7460e-01 -4.2490e-01 -1.7760e-01 -1.0155e+01 -1.0595e+01\n -1.1703e+01  8.3220e-01 -4.9470e-01 -4.4240e-01 -1.2400e-02 -5.1900e-02\n -3.2210e-01 -3.6780e-01  9.9280e-01 -1.0820e-01  1.4968e+01  1.3543e+01\n -2.1940e-01 -4.5620e-01  4.1000e-02 -2.7510e-01  2.1642e+01  4.4000e-02\n  1.6752e+01  1.9769e+01  3.3200e-02  1.3795e+01 -3.6300e-01  1.3382e+01\n  1.1000e+01 -4.9500e-01 -1.2680e-01 -1.9740e-01  1.3139e+01  1.0750e-01\n -5.2510e-01 -2.5790e-01 -2.5420e-01 -1.1250e-01 -3.5200e-01  1.0463e+01\n -6.8840e-01 -1.1800e-02  5.2000e-02 -2.1342e+01  7.0800e-02 -2.1660e-01\n -1.1229e+01  9.5490e-01 -3.6570e-01 -6.3710e-01 -7.5360e-01  2.5582e+01\n -6.4130e-01 -7.5120e-01  3.4854e+01 -2.7060e-01  4.1250e-01  8.8800e-02\n  2.6556e+01 -2.0520e-01  1.1999e+01  6.4310e-01 -8.3670e-01 -5.4880e-01\n -5.9210e-01 -1.2400e-02  3.5004e+01 -4.3350e-01 -5.3910e-01 -3.3010e-01\n  1.8940e-01 -3.3670e-01 -6.7820e-01 -1.2559e+01 -4.8260e-01 -6.1200e-01\n -1.7860e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0370e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  1.0000e+01 -5.5940e-01 -1.2700e-01\n -1.9910e-01 -8.2990e-01 -1.2470e-01 -5.2510e-01 -2.5820e-01 -2.6160e-01\n -2.9580e-01 -3.5200e-01  1.0463e+01 -2.0240e-01 -2.1780e-01 -5.2200e-02\n -2.1342e+01  1.0410e-01 -5.6990e-01 -1.1216e+01  9.5490e-01 -3.6570e-01\n -6.3710e-01 -7.5360e-01  2.5582e+01 -6.4560e-01 -7.7120e-01  1.8422e+01\n  6.3750e-01  5.0380e-01 -2.0110e-01  1.7377e+01  1.4289e+01  1.2568e+01\n  2.5450e-01  5.5000e-02 -5.4920e-01 -5.9560e-01 -1.2400e-02  2.1668e+01\n -4.3430e-01 -5.4380e-01 -3.3010e-01  1.1880e-01 -3.8380e-01 -6.7090e-01\n -1.2280e+00 -4.8090e-01 -5.4720e-01  1.2460e-01 -5.9250e-01 -1.4097e+01\n -6.4780e-01 -6.0790e-01  1.2880e-01 -9.0930e-01 -4.9830e-01 -7.5670e-01\n  2.0000e+01 -5.5940e-01 -9.6400e-02 -1.0940e-01  2.1284e+01  3.7035e+01\n -5.2510e-01 -1.1280e-01 -1.1610e-01  2.4275e+01 -3.5200e-01  1.0463e+01\n -6.6950e-01  2.9740e-01  5.7310e-01 -1.8752e+01  2.4100e-02 -9.2310e-01\n -1.1234e+01  9.5490e-01 -3.6570e-01 -6.3710e-01  9.8570e-01  2.5582e+01\n  5.9500e-01  8.0710e-01  1.1866e+01  2.7846e+01  2.0210e-01  1.3635e+01\n  2.0468e+01 -1.6212e+01  1.1398e+01  7.7260e-01 -1.0545e+01 -1.4260e-01\n -7.8400e-02 -1.2400e-02  7.3470e-01 -1.4180e-01  2.0990e-01 -3.2690e-01\n  4.5021e+01 -3.3670e-01 -3.6750e-01 -1.2733e+01 -4.8380e-01 -4.8730e-01\n -2.6890e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0580e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  2.0000e+00  4.6940e-01 -1.2600e-01\n -1.7830e-01  3.5160e-01 -1.2470e-01  9.7950e-01 -2.3780e-01 -2.2800e-01\n -5.2990e-01 -3.5200e-01  1.0463e+01  3.7690e-01  1.1217e+01  9.9000e-01\n  4.5640e-01  7.3000e-02  4.8990e-01  2.7300e-01  9.5490e-01  2.0680e-01\n  1.6570e-01 -7.5360e-01 -3.9090e-01 -5.6980e-01 -4.6970e-01 -3.0700e-01\n -5.6390e-01 -1.7480e-01 -7.0410e-01 -4.7860e-01  5.5730e-01  9.1960e-01\n -2.6360e-01 -3.8180e-01 -5.0440e-01 -5.5340e-01 -1.2400e-02 -2.2920e-01\n -4.3130e-01 -4.9840e-01 -3.3010e-01 -2.8470e-01 -7.5990e-01 -7.2200e-01\n  2.4994e+01  3.5108e+01 -6.5600e-01 -4.4320e-01 -6.4980e-01  8.8680e-01\n -6.4930e-01 -6.1060e-01 -1.9779e+01 -9.8160e-01 -1.3110e-01 -8.6140e-01\n  1.6000e+01 -6.2410e-01 -1.1840e-01  4.7000e-03 -7.9690e-01 -1.2470e-01\n -1.3510e-01  8.0600e-01  6.3660e-01  3.8000e-02 -3.5200e-01 -7.4540e-01\n -2.7850e-01  9.1300e-02  3.6470e-01  1.9730e-01  7.0800e-02 -9.2310e-01\n -7.5500e-02 -2.9600e-01 -3.6570e-01 -6.3710e-01  1.1610e-01 -3.9090e-01\n  2.2994e+01 -6.0000e-04 -2.3560e-01 -3.2790e-01 -1.7590e-01  1.1802e+01\n -3.2960e-01 -1.2100e+00 -1.0488e+01 -3.9310e-01 -3.9900e-01  1.8213e+01\n  1.4945e+01 -1.2400e-02 -1.3170e-01 -4.0360e-01 -5.0900e-02 -3.5800e-02\n  1.4400e-01  1.4968e+01  1.2410e+00 -2.6510e-01 -2.1850e-01  2.2950e-01\n  1.2660e-01  5.2500e-01  5.2000e-02  1.2860e+00  8.0630e-01 -1.7330e-01\n  1.3795e+01 -3.4890e-01  1.3382e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#%%\n",
        "# Linear Regres\n",
        "X_test\n",
        "\n",
        "LR = LinearRegression()\n",
        "LR.fit(X_train,Y_train)\n",
        "\n",
        "y_prediction =  LR.predict(X_test)\n",
        "\n",
        "print(\"Loss functions:\")\n",
        "print(\"* R-squared =\", r2_score(Y_test, y_prediction))\n",
        "print(\"* RMSE =\", mean_squared_error(Y_test, y_prediction))\n",
        "print(\"* MAE =\", mean_absolute_error(Y_test, y_prediction))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eL5rHoJikOMQ",
        "outputId": "6d482ac9-4154-4000-e483-c13b2d44b5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff82848d647c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_prediction\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         )\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1.5000e+01 -7.3830e-01 -1.2700e-01 -1.9930e-01 -8.2990e-01 -1.2470e-01\n -5.7210e-01 -2.5820e-01 -2.6210e-01 -5.3370e-01 -2.6036e+01 -2.5371e+01\n  1.0551e+01  9.1560e-01  6.7730e-01  4.5640e-01 -9.2000e-03  8.4320e-01\n -6.4490e-01  5.8000e-02 -3.6570e-01  1.6570e-01  4.6400e-01 -3.9090e-01\n -6.3250e-01 -7.0990e-01 -4.3860e-01 -5.6880e-01  7.2100e-02 -8.8380e-01\n -5.6140e-01  6.3760e-01  1.7890e-01  3.8400e-01 -3.0930e-01 -5.4870e-01\n -5.8710e-01 -1.2400e-02 -4.0950e-01 -4.3080e-01 -5.2740e-01 -3.3010e-01\n -2.8470e-01 -7.5990e-01 -5.9780e-01 -9.2550e-01 -3.8910e-01 -6.9200e-01\n -4.6050e-01 -5.1800e-01 -1.0062e+01 -6.4620e-01 -6.0300e-01 -4.7730e-01\n  1.7480e-01 -1.7951e+01 -8.2840e-01  1.5000e+01 -6.2410e-01 -8.9400e-02\n -1.2400e-01 -2.2730e-01 -1.2470e-01 -2.4820e-01 -2.3190e-01 -1.6240e-01\n  3.8200e-02 -3.5200e-01 -7.4540e-01 -5.4070e-01 -1.6604e+01 -1.4071e+01\n  1.9730e-01 -2.1570e-01 -9.2310e-01  9.9700e-02 -2.9600e-01 -3.6570e-01\n -6.3710e-01 -2.3180e-01 -3.9090e-01 -4.5900e-01 -2.1950e-01 -1.1890e-01\n -1.7460e-01 -1.7460e-01 -4.2490e-01 -1.7760e-01 -1.0155e+01 -1.0595e+01\n -1.1703e+01  8.3220e-01 -4.9470e-01 -4.4240e-01 -1.2400e-02 -5.1900e-02\n -3.2210e-01 -3.6780e-01  9.9280e-01 -1.0820e-01  1.4968e+01  1.3543e+01\n -2.1940e-01 -4.5620e-01  4.1000e-02 -2.7510e-01  2.1642e+01  4.4000e-02\n  1.6752e+01  1.9769e+01  3.3200e-02  1.3795e+01 -3.6300e-01  1.3382e+01\n  1.1000e+01 -4.9500e-01 -1.2680e-01 -1.9740e-01  1.3139e+01  1.0750e-01\n -5.2510e-01 -2.5790e-01 -2.5420e-01 -1.1250e-01 -3.5200e-01  1.0463e+01\n -6.8840e-01 -1.1800e-02  5.2000e-02 -2.1342e+01  7.0800e-02 -2.1660e-01\n -1.1229e+01  9.5490e-01 -3.6570e-01 -6.3710e-01 -7.5360e-01  2.5582e+01\n -6.4130e-01 -7.5120e-01  3.4854e+01 -2.7060e-01  4.1250e-01  8.8800e-02\n  2.6556e+01 -2.0520e-01  1.1999e+01  6.4310e-01 -8.3670e-01 -5.4880e-01\n -5.9210e-01 -1.2400e-02  3.5004e+01 -4.3350e-01 -5.3910e-01 -3.3010e-01\n  1.8940e-01 -3.3670e-01 -6.7820e-01 -1.2559e+01 -4.8260e-01 -6.1200e-01\n -1.7860e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0370e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  1.0000e+01 -5.5940e-01 -1.2700e-01\n -1.9910e-01 -8.2990e-01 -1.2470e-01 -5.2510e-01 -2.5820e-01 -2.6160e-01\n -2.9580e-01 -3.5200e-01  1.0463e+01 -2.0240e-01 -2.1780e-01 -5.2200e-02\n -2.1342e+01  1.0410e-01 -5.6990e-01 -1.1216e+01  9.5490e-01 -3.6570e-01\n -6.3710e-01 -7.5360e-01  2.5582e+01 -6.4560e-01 -7.7120e-01  1.8422e+01\n  6.3750e-01  5.0380e-01 -2.0110e-01  1.7377e+01  1.4289e+01  1.2568e+01\n  2.5450e-01  5.5000e-02 -5.4920e-01 -5.9560e-01 -1.2400e-02  2.1668e+01\n -4.3430e-01 -5.4380e-01 -3.3010e-01  1.1880e-01 -3.8380e-01 -6.7090e-01\n -1.2280e+00 -4.8090e-01 -5.4720e-01  1.2460e-01 -5.9250e-01 -1.4097e+01\n -6.4780e-01 -6.0790e-01  1.2880e-01 -9.0930e-01 -4.9830e-01 -7.5670e-01\n  2.0000e+01 -5.5940e-01 -9.6400e-02 -1.0940e-01  2.1284e+01  3.7035e+01\n -5.2510e-01 -1.1280e-01 -1.1610e-01  2.4275e+01 -3.5200e-01  1.0463e+01\n -6.6950e-01  2.9740e-01  5.7310e-01 -1.8752e+01  2.4100e-02 -9.2310e-01\n -1.1234e+01  9.5490e-01 -3.6570e-01 -6.3710e-01  9.8570e-01  2.5582e+01\n  5.9500e-01  8.0710e-01  1.1866e+01  2.7846e+01  2.0210e-01  1.3635e+01\n  2.0468e+01 -1.6212e+01  1.1398e+01  7.7260e-01 -1.0545e+01 -1.4260e-01\n -7.8400e-02 -1.2400e-02  7.3470e-01 -1.4180e-01  2.0990e-01 -3.2690e-01\n  4.5021e+01 -3.3670e-01 -3.6750e-01 -1.2733e+01 -4.8380e-01 -4.8730e-01\n -2.6890e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0580e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  2.0000e+00  4.6940e-01 -1.2600e-01\n -1.7830e-01  3.5160e-01 -1.2470e-01  9.7950e-01 -2.3780e-01 -2.2800e-01\n -5.2990e-01 -3.5200e-01  1.0463e+01  3.7690e-01  1.1217e+01  9.9000e-01\n  4.5640e-01  7.3000e-02  4.8990e-01  2.7300e-01  9.5490e-01  2.0680e-01\n  1.6570e-01 -7.5360e-01 -3.9090e-01 -5.6980e-01 -4.6970e-01 -3.0700e-01\n -5.6390e-01 -1.7480e-01 -7.0410e-01 -4.7860e-01  5.5730e-01  9.1960e-01\n -2.6360e-01 -3.8180e-01 -5.0440e-01 -5.5340e-01 -1.2400e-02 -2.2920e-01\n -4.3130e-01 -4.9840e-01 -3.3010e-01 -2.8470e-01 -7.5990e-01 -7.2200e-01\n  2.4994e+01  3.5108e+01 -6.5600e-01 -4.4320e-01 -6.4980e-01  8.8680e-01\n -6.4930e-01 -6.1060e-01 -1.9779e+01 -9.8160e-01 -1.3110e-01 -8.6140e-01\n  1.6000e+01 -6.2410e-01 -1.1840e-01  4.7000e-03 -7.9690e-01 -1.2470e-01\n -1.3510e-01  8.0600e-01  6.3660e-01  3.8000e-02 -3.5200e-01 -7.4540e-01\n -2.7850e-01  9.1300e-02  3.6470e-01  1.9730e-01  7.0800e-02 -9.2310e-01\n -7.5500e-02 -2.9600e-01 -3.6570e-01 -6.3710e-01  1.1610e-01 -3.9090e-01\n  2.2994e+01 -6.0000e-04 -2.3560e-01 -3.2790e-01 -1.7590e-01  1.1802e+01\n -3.2960e-01 -1.2100e+00 -1.0488e+01 -3.9310e-01 -3.9900e-01  1.8213e+01\n  1.4945e+01 -1.2400e-02 -1.3170e-01 -4.0360e-01 -5.0900e-02 -3.5800e-02\n  1.4400e-01  1.4968e+01  1.2410e+00 -2.6510e-01 -2.1850e-01  2.2950e-01\n  1.2660e-01  5.2500e-01  5.2000e-02  1.2860e+00  8.0630e-01 -1.7330e-01\n  1.3795e+01 -3.4890e-01  1.3382e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#%%\n",
        "# ElasticNet Regres\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "e_net = ElasticNet(alpha = 0.0001)\n",
        "e_net.fit(X_train, Y_train)\n",
        "\n",
        "y_pred_elastic = e_net.predict(X_test)\n",
        "\n",
        "print(\"Loss functions:\")\n",
        "print(\"* R-squared =\", r2_score(Y_test, y_pred_elastic))\n",
        "print(\"* RMSE =\", mean_squared_error(Y_test, y_pred_elastic))\n",
        "print(\"* MAE =\", mean_absolute_error(Y_test, y_pred_elastic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H7Z_pl5WkQQ9",
        "outputId": "26271fa9-2c6a-49c4-bd8c-d631fc5bb11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dba698a565d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0me_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0me_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred_elastic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_copied\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             )\n\u001b[1;32m    945\u001b[0m             y = check_array(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1.5000e+01 -7.3830e-01 -1.2700e-01 -1.9930e-01 -8.2990e-01 -1.2470e-01\n -5.7210e-01 -2.5820e-01 -2.6210e-01 -5.3370e-01 -2.6036e+01 -2.5371e+01\n  1.0551e+01  9.1560e-01  6.7730e-01  4.5640e-01 -9.2000e-03  8.4320e-01\n -6.4490e-01  5.8000e-02 -3.6570e-01  1.6570e-01  4.6400e-01 -3.9090e-01\n -6.3250e-01 -7.0990e-01 -4.3860e-01 -5.6880e-01  7.2100e-02 -8.8380e-01\n -5.6140e-01  6.3760e-01  1.7890e-01  3.8400e-01 -3.0930e-01 -5.4870e-01\n -5.8710e-01 -1.2400e-02 -4.0950e-01 -4.3080e-01 -5.2740e-01 -3.3010e-01\n -2.8470e-01 -7.5990e-01 -5.9780e-01 -9.2550e-01 -3.8910e-01 -6.9200e-01\n -4.6050e-01 -5.1800e-01 -1.0062e+01 -6.4620e-01 -6.0300e-01 -4.7730e-01\n  1.7480e-01 -1.7951e+01 -8.2840e-01  1.5000e+01 -6.2410e-01 -8.9400e-02\n -1.2400e-01 -2.2730e-01 -1.2470e-01 -2.4820e-01 -2.3190e-01 -1.6240e-01\n  3.8200e-02 -3.5200e-01 -7.4540e-01 -5.4070e-01 -1.6604e+01 -1.4071e+01\n  1.9730e-01 -2.1570e-01 -9.2310e-01  9.9700e-02 -2.9600e-01 -3.6570e-01\n -6.3710e-01 -2.3180e-01 -3.9090e-01 -4.5900e-01 -2.1950e-01 -1.1890e-01\n -1.7460e-01 -1.7460e-01 -4.2490e-01 -1.7760e-01 -1.0155e+01 -1.0595e+01\n -1.1703e+01  8.3220e-01 -4.9470e-01 -4.4240e-01 -1.2400e-02 -5.1900e-02\n -3.2210e-01 -3.6780e-01  9.9280e-01 -1.0820e-01  1.4968e+01  1.3543e+01\n -2.1940e-01 -4.5620e-01  4.1000e-02 -2.7510e-01  2.1642e+01  4.4000e-02\n  1.6752e+01  1.9769e+01  3.3200e-02  1.3795e+01 -3.6300e-01  1.3382e+01\n  1.1000e+01 -4.9500e-01 -1.2680e-01 -1.9740e-01  1.3139e+01  1.0750e-01\n -5.2510e-01 -2.5790e-01 -2.5420e-01 -1.1250e-01 -3.5200e-01  1.0463e+01\n -6.8840e-01 -1.1800e-02  5.2000e-02 -2.1342e+01  7.0800e-02 -2.1660e-01\n -1.1229e+01  9.5490e-01 -3.6570e-01 -6.3710e-01 -7.5360e-01  2.5582e+01\n -6.4130e-01 -7.5120e-01  3.4854e+01 -2.7060e-01  4.1250e-01  8.8800e-02\n  2.6556e+01 -2.0520e-01  1.1999e+01  6.4310e-01 -8.3670e-01 -5.4880e-01\n -5.9210e-01 -1.2400e-02  3.5004e+01 -4.3350e-01 -5.3910e-01 -3.3010e-01\n  1.8940e-01 -3.3670e-01 -6.7820e-01 -1.2559e+01 -4.8260e-01 -6.1200e-01\n -1.7860e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0370e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  1.0000e+01 -5.5940e-01 -1.2700e-01\n -1.9910e-01 -8.2990e-01 -1.2470e-01 -5.2510e-01 -2.5820e-01 -2.6160e-01\n -2.9580e-01 -3.5200e-01  1.0463e+01 -2.0240e-01 -2.1780e-01 -5.2200e-02\n -2.1342e+01  1.0410e-01 -5.6990e-01 -1.1216e+01  9.5490e-01 -3.6570e-01\n -6.3710e-01 -7.5360e-01  2.5582e+01 -6.4560e-01 -7.7120e-01  1.8422e+01\n  6.3750e-01  5.0380e-01 -2.0110e-01  1.7377e+01  1.4289e+01  1.2568e+01\n  2.5450e-01  5.5000e-02 -5.4920e-01 -5.9560e-01 -1.2400e-02  2.1668e+01\n -4.3430e-01 -5.4380e-01 -3.3010e-01  1.1880e-01 -3.8380e-01 -6.7090e-01\n -1.2280e+00 -4.8090e-01 -5.4720e-01  1.2460e-01 -5.9250e-01 -1.4097e+01\n -6.4780e-01 -6.0790e-01  1.2880e-01 -9.0930e-01 -4.9830e-01 -7.5670e-01\n  2.0000e+01 -5.5940e-01 -9.6400e-02 -1.0940e-01  2.1284e+01  3.7035e+01\n -5.2510e-01 -1.1280e-01 -1.1610e-01  2.4275e+01 -3.5200e-01  1.0463e+01\n -6.6950e-01  2.9740e-01  5.7310e-01 -1.8752e+01  2.4100e-02 -9.2310e-01\n -1.1234e+01  9.5490e-01 -3.6570e-01 -6.3710e-01  9.8570e-01  2.5582e+01\n  5.9500e-01  8.0710e-01  1.1866e+01  2.7846e+01  2.0210e-01  1.3635e+01\n  2.0468e+01 -1.6212e+01  1.1398e+01  7.7260e-01 -1.0545e+01 -1.4260e-01\n -7.8400e-02 -1.2400e-02  7.3470e-01 -1.4180e-01  2.0990e-01 -3.2690e-01\n  4.5021e+01 -3.3670e-01 -3.6750e-01 -1.2733e+01 -4.8380e-01 -4.8730e-01\n -2.6890e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0580e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  2.0000e+00  4.6940e-01 -1.2600e-01\n -1.7830e-01  3.5160e-01 -1.2470e-01  9.7950e-01 -2.3780e-01 -2.2800e-01\n -5.2990e-01 -3.5200e-01  1.0463e+01  3.7690e-01  1.1217e+01  9.9000e-01\n  4.5640e-01  7.3000e-02  4.8990e-01  2.7300e-01  9.5490e-01  2.0680e-01\n  1.6570e-01 -7.5360e-01 -3.9090e-01 -5.6980e-01 -4.6970e-01 -3.0700e-01\n -5.6390e-01 -1.7480e-01 -7.0410e-01 -4.7860e-01  5.5730e-01  9.1960e-01\n -2.6360e-01 -3.8180e-01 -5.0440e-01 -5.5340e-01 -1.2400e-02 -2.2920e-01\n -4.3130e-01 -4.9840e-01 -3.3010e-01 -2.8470e-01 -7.5990e-01 -7.2200e-01\n  2.4994e+01  3.5108e+01 -6.5600e-01 -4.4320e-01 -6.4980e-01  8.8680e-01\n -6.4930e-01 -6.1060e-01 -1.9779e+01 -9.8160e-01 -1.3110e-01 -8.6140e-01\n  1.6000e+01 -6.2410e-01 -1.1840e-01  4.7000e-03 -7.9690e-01 -1.2470e-01\n -1.3510e-01  8.0600e-01  6.3660e-01  3.8000e-02 -3.5200e-01 -7.4540e-01\n -2.7850e-01  9.1300e-02  3.6470e-01  1.9730e-01  7.0800e-02 -9.2310e-01\n -7.5500e-02 -2.9600e-01 -3.6570e-01 -6.3710e-01  1.1610e-01 -3.9090e-01\n  2.2994e+01 -6.0000e-04 -2.3560e-01 -3.2790e-01 -1.7590e-01  1.1802e+01\n -3.2960e-01 -1.2100e+00 -1.0488e+01 -3.9310e-01 -3.9900e-01  1.8213e+01\n  1.4945e+01 -1.2400e-02 -1.3170e-01 -4.0360e-01 -5.0900e-02 -3.5800e-02\n  1.4400e-01  1.4968e+01  1.2410e+00 -2.6510e-01 -2.1850e-01  2.2950e-01\n  1.2660e-01  5.2500e-01  5.2000e-02  1.2860e+00  8.0630e-01 -1.7330e-01\n  1.3795e+01 -3.4890e-01  1.3382e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#%%\n",
        "# SVR\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "regressor=SVR(kernel='linear',degree=0.5)\n",
        "\n",
        "regressor.fit(X_train,Y_train)\n",
        "\n",
        "pred=regressor.predict(X_test)\n",
        "\n",
        "print(\"Loss functions:\")\n",
        "print(\"* R-squared =\", r2_score(Y_test, pred))\n",
        "print(\"* RMSE =\", mean_squared_error(Y_test, pred))\n",
        "print(\"* MAE =\", mean_absolute_error(Y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K_yY3qgOkRze",
        "outputId": "f35864ef-34a4-49ef-aa51-ae7cdc2e96c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c4a33ca6b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1.5000e+01 -7.3830e-01 -1.2700e-01 -1.9930e-01 -8.2990e-01 -1.2470e-01\n -5.7210e-01 -2.5820e-01 -2.6210e-01 -5.3370e-01 -2.6036e+01 -2.5371e+01\n  1.0551e+01  9.1560e-01  6.7730e-01  4.5640e-01 -9.2000e-03  8.4320e-01\n -6.4490e-01  5.8000e-02 -3.6570e-01  1.6570e-01  4.6400e-01 -3.9090e-01\n -6.3250e-01 -7.0990e-01 -4.3860e-01 -5.6880e-01  7.2100e-02 -8.8380e-01\n -5.6140e-01  6.3760e-01  1.7890e-01  3.8400e-01 -3.0930e-01 -5.4870e-01\n -5.8710e-01 -1.2400e-02 -4.0950e-01 -4.3080e-01 -5.2740e-01 -3.3010e-01\n -2.8470e-01 -7.5990e-01 -5.9780e-01 -9.2550e-01 -3.8910e-01 -6.9200e-01\n -4.6050e-01 -5.1800e-01 -1.0062e+01 -6.4620e-01 -6.0300e-01 -4.7730e-01\n  1.7480e-01 -1.7951e+01 -8.2840e-01  1.5000e+01 -6.2410e-01 -8.9400e-02\n -1.2400e-01 -2.2730e-01 -1.2470e-01 -2.4820e-01 -2.3190e-01 -1.6240e-01\n  3.8200e-02 -3.5200e-01 -7.4540e-01 -5.4070e-01 -1.6604e+01 -1.4071e+01\n  1.9730e-01 -2.1570e-01 -9.2310e-01  9.9700e-02 -2.9600e-01 -3.6570e-01\n -6.3710e-01 -2.3180e-01 -3.9090e-01 -4.5900e-01 -2.1950e-01 -1.1890e-01\n -1.7460e-01 -1.7460e-01 -4.2490e-01 -1.7760e-01 -1.0155e+01 -1.0595e+01\n -1.1703e+01  8.3220e-01 -4.9470e-01 -4.4240e-01 -1.2400e-02 -5.1900e-02\n -3.2210e-01 -3.6780e-01  9.9280e-01 -1.0820e-01  1.4968e+01  1.3543e+01\n -2.1940e-01 -4.5620e-01  4.1000e-02 -2.7510e-01  2.1642e+01  4.4000e-02\n  1.6752e+01  1.9769e+01  3.3200e-02  1.3795e+01 -3.6300e-01  1.3382e+01\n  1.1000e+01 -4.9500e-01 -1.2680e-01 -1.9740e-01  1.3139e+01  1.0750e-01\n -5.2510e-01 -2.5790e-01 -2.5420e-01 -1.1250e-01 -3.5200e-01  1.0463e+01\n -6.8840e-01 -1.1800e-02  5.2000e-02 -2.1342e+01  7.0800e-02 -2.1660e-01\n -1.1229e+01  9.5490e-01 -3.6570e-01 -6.3710e-01 -7.5360e-01  2.5582e+01\n -6.4130e-01 -7.5120e-01  3.4854e+01 -2.7060e-01  4.1250e-01  8.8800e-02\n  2.6556e+01 -2.0520e-01  1.1999e+01  6.4310e-01 -8.3670e-01 -5.4880e-01\n -5.9210e-01 -1.2400e-02  3.5004e+01 -4.3350e-01 -5.3910e-01 -3.3010e-01\n  1.8940e-01 -3.3670e-01 -6.7820e-01 -1.2559e+01 -4.8260e-01 -6.1200e-01\n -1.7860e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0370e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  1.0000e+01 -5.5940e-01 -1.2700e-01\n -1.9910e-01 -8.2990e-01 -1.2470e-01 -5.2510e-01 -2.5820e-01 -2.6160e-01\n -2.9580e-01 -3.5200e-01  1.0463e+01 -2.0240e-01 -2.1780e-01 -5.2200e-02\n -2.1342e+01  1.0410e-01 -5.6990e-01 -1.1216e+01  9.5490e-01 -3.6570e-01\n -6.3710e-01 -7.5360e-01  2.5582e+01 -6.4560e-01 -7.7120e-01  1.8422e+01\n  6.3750e-01  5.0380e-01 -2.0110e-01  1.7377e+01  1.4289e+01  1.2568e+01\n  2.5450e-01  5.5000e-02 -5.4920e-01 -5.9560e-01 -1.2400e-02  2.1668e+01\n -4.3430e-01 -5.4380e-01 -3.3010e-01  1.1880e-01 -3.8380e-01 -6.7090e-01\n -1.2280e+00 -4.8090e-01 -5.4720e-01  1.2460e-01 -5.9250e-01 -1.4097e+01\n -6.4780e-01 -6.0790e-01  1.2880e-01 -9.0930e-01 -4.9830e-01 -7.5670e-01\n  2.0000e+01 -5.5940e-01 -9.6400e-02 -1.0940e-01  2.1284e+01  3.7035e+01\n -5.2510e-01 -1.1280e-01 -1.1610e-01  2.4275e+01 -3.5200e-01  1.0463e+01\n -6.6950e-01  2.9740e-01  5.7310e-01 -1.8752e+01  2.4100e-02 -9.2310e-01\n -1.1234e+01  9.5490e-01 -3.6570e-01 -6.3710e-01  9.8570e-01  2.5582e+01\n  5.9500e-01  8.0710e-01  1.1866e+01  2.7846e+01  2.0210e-01  1.3635e+01\n  2.0468e+01 -1.6212e+01  1.1398e+01  7.7260e-01 -1.0545e+01 -1.4260e-01\n -7.8400e-02 -1.2400e-02  7.3470e-01 -1.4180e-01  2.0990e-01 -3.2690e-01\n  4.5021e+01 -3.3670e-01 -3.6750e-01 -1.2733e+01 -4.8380e-01 -4.8730e-01\n -2.6890e-01 -6.0400e-01 -1.4229e+01 -6.4560e-01 -6.0580e-01  1.9337e+01\n -9.0930e-01  2.4046e+01 -7.5670e-01  2.0000e+00  4.6940e-01 -1.2600e-01\n -1.7830e-01  3.5160e-01 -1.2470e-01  9.7950e-01 -2.3780e-01 -2.2800e-01\n -5.2990e-01 -3.5200e-01  1.0463e+01  3.7690e-01  1.1217e+01  9.9000e-01\n  4.5640e-01  7.3000e-02  4.8990e-01  2.7300e-01  9.5490e-01  2.0680e-01\n  1.6570e-01 -7.5360e-01 -3.9090e-01 -5.6980e-01 -4.6970e-01 -3.0700e-01\n -5.6390e-01 -1.7480e-01 -7.0410e-01 -4.7860e-01  5.5730e-01  9.1960e-01\n -2.6360e-01 -3.8180e-01 -5.0440e-01 -5.5340e-01 -1.2400e-02 -2.2920e-01\n -4.3130e-01 -4.9840e-01 -3.3010e-01 -2.8470e-01 -7.5990e-01 -7.2200e-01\n  2.4994e+01  3.5108e+01 -6.5600e-01 -4.4320e-01 -6.4980e-01  8.8680e-01\n -6.4930e-01 -6.1060e-01 -1.9779e+01 -9.8160e-01 -1.3110e-01 -8.6140e-01\n  1.6000e+01 -6.2410e-01 -1.1840e-01  4.7000e-03 -7.9690e-01 -1.2470e-01\n -1.3510e-01  8.0600e-01  6.3660e-01  3.8000e-02 -3.5200e-01 -7.4540e-01\n -2.7850e-01  9.1300e-02  3.6470e-01  1.9730e-01  7.0800e-02 -9.2310e-01\n -7.5500e-02 -2.9600e-01 -3.6570e-01 -6.3710e-01  1.1610e-01 -3.9090e-01\n  2.2994e+01 -6.0000e-04 -2.3560e-01 -3.2790e-01 -1.7590e-01  1.1802e+01\n -3.2960e-01 -1.2100e+00 -1.0488e+01 -3.9310e-01 -3.9900e-01  1.8213e+01\n  1.4945e+01 -1.2400e-02 -1.3170e-01 -4.0360e-01 -5.0900e-02 -3.5800e-02\n  1.4400e-01  1.4968e+01  1.2410e+00 -2.6510e-01 -2.1850e-01  2.2950e-01\n  1.2660e-01  5.2500e-01  5.2000e-02  1.2860e+00  8.0630e-01 -1.7330e-01\n  1.3795e+01 -3.4890e-01  1.3382e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH/yZlzTA3loabDlgnpI9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}